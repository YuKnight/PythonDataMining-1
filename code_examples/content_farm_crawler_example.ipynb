{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 此筆記本目的是讓大家有個概念，了解如何使用Python爬蟲。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所需套件：bs4, selenium, pandas, lxml。\n",
    "\n",
    "另外，我們還需要瀏覽器[chromedriver](https://sites.google.com/a/chromium.org/chromedriver/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlMain=\"http://www.cacanews.com/cat91/92?sort=quality\" # 想從這裡抓資料\n",
    "urlLogin='http://www.cacanews.com/site/login' # 要先登入才能抓到我們想要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser=webdriver.Chrome(\"/Users/chweng/Desktop/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromePath=\"/Users/chweng/Desktop/chromedriver\"\n",
    "browser=webdriver.Chrome(chromePath) # 開啟測試用的chrome瀏覽器\n",
    "browser.get(urlLogin) # 以瀏覽器進入登入帳號的頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到帳密輸入區塊的ID後，輸入帳密\n",
    "\n",
    "emailID=browser.find_element_by_id(\"LoginForm_username\")\n",
    "emailID.send_keys(\"chihung@honghutech.com\") # 輸入帳號\n",
    "\n",
    "passwd=browser.find_element_by_id(\"LoginForm_password\")\n",
    "passwd.send_keys(\"tmp12345\") # 輸入密碼\n",
    "\n",
    "# 找到登入按鈕，並按下登入按鈕以登入頁面\n",
    "signin=browser.find_element_by_class_name('btn-primary')\n",
    "signin.click() # 登入頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 登入完畢後，即可去目標頁面爬取我們想要的資料\n",
    "\n",
    "browser.get(urlMain)\n",
    "webText=browser.page_source # 得到網頁原始碼\n",
    "soup=BeautifulSoup(webText,'lxml') # 將網頁原始碼交給Beautifulsoup解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已經得到目標頁面原始碼。故可以先將測試用瀏覽器關閉\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到名稱為h3, 並且class是media-head開頭的 HTML tag\n",
    "divs=soup.select('h3[class^=\"media-head\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將標題，和該標題發佈的日期存成兩個清單\n",
    "titles=[]\n",
    "dates=[]\n",
    "for div in divs:\n",
    "    titles.append(div.text.split(divs[0].span.text)[1].strip())\n",
    "    dates.append(div.next_sibling.next_sibling.text.split(\"|\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將清單轉存Pandas資料表，以利之後的資料處理\n",
    "df=pd.DataFrame({\"title\":titles,\"dates\":dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將爬取得來的資料轉成csv檔案儲存\n",
    "df.to_csv(\"content_farm_example.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
