{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本筆記將帶大家用Keras建模\n",
    "# 此範例使用MNIST手寫數字資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I. 資料準備](#I.-資料準備)\n",
    "\n",
    "[II. Softmax Regression](#II.-Softmax-Regression)\n",
    "\n",
    "[III. AlexNet-like Network](#III.-AlexNet-like-Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='mxnet')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='keras.utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "print('retrieving MNIST data...')\n",
    "theurl = 'https://github.com/chi-hung/PythonTutorial/raw/master/datasets/mnist.tar.gz'\n",
    "filename='mnist.tar.gz'\n",
    "name, hdrs = urlretrieve(theurl, filename)\n",
    "\n",
    "print('extracting MNIST data...')\n",
    "res=!tar -xvf {filename}\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. 資料準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filePathsGen(rootPath):\n",
    "    paths=[]\n",
    "    dirs=[]\n",
    "    for dirPath,dirNames,fileNames in os.walk(rootPath):\n",
    "        for fileName in fileNames:\n",
    "            fullPath=os.path.join(dirPath,fileName)\n",
    "            paths.append((int(dirPath[len(rootPath) ]),fullPath))\n",
    "        dirs.append(dirNames)\n",
    "    return dirs,paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs,paths=filePathsGen('mnist/') #載入圖片路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPath=pd.DataFrame(paths,columns=['class','path']) #圖片路徑存成Pandas資料表\n",
    "dfPath.head(5) # 看資料表前5個row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 利用Pandas, 可迅速了解每個資料夾裡面有幾張圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依照class分群後，數各群的數量，並繪圖\n",
    "dfCountPerClass=dfPath.groupby('class').count()\n",
    "dfCountPerClass.rename(columns={'path':'amount of figures'},inplace=True)\n",
    "dfCountPerClass.plot(kind='bar',rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  將圖片路徑資訊分成train($70\\%$), val($10\\%$), test($10\\%$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFiguresShuffled=dfPath.sample(frac=1) # 打亂一下path data\n",
    "\n",
    "#dfFrac=dfFiguresShuffled\n",
    "dfFrac=dfFiguresShuffled.sample(frac=0.3) # 以下範例，我們只取原資料集的30%來做使用，\n",
    "                                            # 這是為了利於在課堂中快速演練。\n",
    "    \n",
    "train=dfFrac.sample(frac=0.8) # 將path data隨機取樣，80%的path data當train\n",
    "test=dfFrac.drop(train.index) # 20%的path data當test\n",
    "\n",
    "trainVal=train.sample(frac=1/8) # 將train再切1/8做驗證用資料, 存至trainVal\n",
    "train=train.drop(trainVal.index)# 將train的7/8留著，丟去剛切出去的1/8\n",
    "\n",
    "#最終，整體資料拿70%當train, 10%當train_val, 20%當test。\n",
    "print('shape(all figures)=\\t\\t',dfPath.shape)\n",
    "print('shape(fraction of figures)=\\t',dfFrac.shape)\n",
    "print('shape(train)=\\t\\t\\t',train.shape)\n",
    "print('shape(trainVal)=\\t\\t',trainVal.shape)\n",
    "print('shape(test)=\\t\\t\\t',test.shape)\n",
    "\n",
    "#隨便抓三張圖來看\n",
    "for j in range(3):\n",
    "    img=plt.imread(train['path'].iloc[j])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####  將圖片載入，存成數值矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoad(dfPath):\n",
    "    paths=dfPath['path'].values\n",
    "    x=np.zeros((len(paths),28,28),dtype=np.float32 )\n",
    "\n",
    "    for j in range(len(paths)):\n",
    "        x[j,:,:]=plt.imread(paths[j])/255\n",
    "\n",
    "    y=dfPath['class'].values\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=dataLoad(train)\n",
    "trainValX,trainValY=dataLoad(trainVal)\n",
    "testX,testY=dataLoad(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:\\t',trainX.shape,trainY.shape)\n",
    "print('trainVal:',trainValX.shape,trainValY.shape)\n",
    "print('test:\\t',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將y 轉成one hot形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "trainYOneHot=np.float32( enc.fit_transform(trainY.reshape(-1,1)) \\\n",
    "                .toarray() )\n",
    "\n",
    "trainValYOneHot=np.float32( enc.fit_transform(trainValY.reshape(-1,1)) \\\n",
    "                   .toarray() )\n",
    "\n",
    "testYOneHot=np.float32( enc.fit_transform(testY.reshape(-1,1)) \\\n",
    "               .toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train:\\t',trainX.shape,trainY.shape)\n",
    "print('trainVal:',trainValX.shape,trainValY.shape)\n",
    "print('test:\\t',testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(10, activation='softmax') )\n",
    "\n",
    "sgd=SGD(lr=0.2, momentum=0.0, decay=0.0)\n",
    "model.compile(optimizer='sgd',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist=model.fit(trainX, trainYOneHot,\n",
    "               epochs=20, batch_size=128,\n",
    "               validation_data=(trainValX,trainValYOneHot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testYOneHot, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score # [loss , accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    print( model.predict(trainX[j:j+1,:]).argmax() )\n",
    "    print( trainYOneHot[j].argmax() )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(hist.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "儲存模型和權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('first_try.json', 'w') as jsOut:\n",
    "    json.dump(model.to_json(), jsOut)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入存好的模型和權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_try.json', 'r') as jsIn:\n",
    "    modelJson=json.load(jsIn)\n",
    "    \n",
    "modelLoaded=model_from_json(modelJson)\n",
    "modelLoaded.load_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=model.predict(testX).argmax(axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print( classification_report(predY,testY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. AlexNet-like Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=trainX.reshape(trainX.shape[0],1,trainX.shape[1],trainX.shape[2])\n",
    "trainValX=trainValX.reshape(trainValX.shape[0],1,trainValX.shape[1],trainValX.shape[2])\n",
    "testX=testX.reshape(testX.shape[0],1,testX.shape[1],testX.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD,Adam,Adamax\n",
    "#from keras.losses import categorical_crossentropy\n",
    "\n",
    "input_shape=(1,28,28)\n",
    "\n",
    "model = Sequential()\n",
    "#conv1\n",
    "model.add(Conv2D(32, (3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(1,28,28)))\n",
    "#conv2\n",
    "model.add(Conv2D(64, (3,3), activation='relu')\n",
    "         )\n",
    "#pool1\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))\n",
    "         )\n",
    "#dropout1\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "#dense1\n",
    "model.add(Dense(128, activation='relu')\n",
    "         )\n",
    "#dropout2\n",
    "model.add(Dropout(0.5))\n",
    "#dense2\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01,momentum=0.1),\n",
    "              metrics=['accuracy'],\n",
    "              context=['gpu(0)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "hist=model.fit(trainX, trainYOneHot, \n",
    "               epochs=20,\n",
    "               batch_size=32,\n",
    "               validation_data=(trainValX,trainValYOneHot),\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'],ms=5,marker='o',label='accuracy')\n",
    "plt.plot(hist.history['val_acc'],ms=5,marker='o',label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=model.predict(testX).argmax(axis=1)\n",
    "from sklearn.metrics import classification_report\n",
    "print( classification_report(predY,testY) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
